{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Чудесный мир Word Embeddings: какие они бывают и зачем нужны?](https://habrahabr.ru/company/ods/blog/329410/)\n",
    "* [Applied Text Mining in Python](https://www.coursera.org/learn/python-text-mining)\n",
    "* [Amazon Reviews: Unlocked Mobile Phones](https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones)\n",
    "* [Machine Learning, NLP: Text Classification using scikit-learn, python and NLTK](https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a)\n",
    "* [Как я сделал свои «Яндекс.Новости»](https://vc.ru/29708-kak-ya-sdelal-svoi-yandeks-novosti)\n",
    "* [fastText](https://github.com/facebookresearch/fastText)\n",
    "* [Text Classification & Word Representations using FastText (An NLP library by Facebook)](https://www.analyticsvidhya.com/blog/2017/07/word-representations-text-classification-using-fasttext-nlp-facebook/)\n",
    "* [Тексты // Открытый курс машинного обучения. Тема 6. Построение и отбор признаков](https://habrahabr.ru/company/ods/blog/325422/#teksty)\n",
    "* [Word2Vec в примерах](https://habrahabr.ru/post/249215/)\n",
    "* [Русскоязычные модели для Word2Vec](http://rusvectores.org/ru/models/)\n",
    "* [Russian Distributional Thesaurus](https://nlpub.ru/Russian_Distributional_Thesaurus)\n",
    "* [Gensim](https://radimrehurek.com/gensim/index.html)\n",
    "* [A Survey on Hate Speech Detection using Natural Language Processing](http://www.aclweb.org/anthology/W17-1101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Понятие интеллектуального анализа текста (text mining) и его отличие от контент-анализа\n",
    "Data mining — это междисциплинарная область знания, находящая на пересечении традиционного статистического анализа, искусственного ин- теллекта, машинного обучения и развития больших баз данных. Можно даже сказать, что data mining — это новая философия, новый взгляд на анализ данных. Суть философии data mining частично выражена в названии этой области знания, которое со- стоит из двух понятий: поиск ценной информации в большой базе данных (data) и добыча горной руды (mining). Именно в просеивании через сито своих инструментов огромного количества «сырых», часто неструктурированных данных в поисках самородков, т. е. осмысленной, нетриви- альной информации — знаний. Более верным названием для этого процесса было бы «knowledge mining from data» (добыча знаний из данных)\n",
    "\n",
    "Исходное определение термина, которое дал наш бывший соотечественник Григорий Пятнецкий-Шапито, звучит следующим образом: «Data mining — это процесс обнаружения в сырых данных ранее неизвестных нетривиальных практически полезных и доступных интерпретации знаний, необходимых для принятия решений в различных сферах человеческой деятельности».\n",
    "\n",
    "Специфической областью data mining, нацеленной на анализ текстовых данных является text mining – интеллектуальный анализ текста. По аналогии с термином data mining термину text mining можно дать следующее определение – это нетривиальный процесс обнаружения действительно новых, потенциально полезных и понятных шаблонов в неструктурированных текстовых данных.\n",
    "\n",
    "Самым популярным вариантом методологии data mining является CRISP-DM (CRoss Industry Standard Process for Data Mining) – Межотраслевой стандартный процесс для data mining.\n",
    "\n",
    "Так как главное отличие text mining от data mining заключается в том, что первый специализируется на определённом типе данных, с небольшими изменениями CRISP-DM можно применить и для ана- лиза текстовых данных. Весь цикл обработки данных это методологии представлен шестью последовательными этапами\n",
    "\n",
    "**Этап 1. Определение целей исследования**. С этого начинается практически любая осмысленная деятельность. Грамотная постановка цели требует глубокого понимания всех аспектов ситуации, в которой проводится исследование, и чёткого определения результата, который мы хотим получить. Для этого необходимо изучить проблему, на решение которой направлено исследование.\n",
    "\n",
    "**Этап 2. Оценка доступности и характера данных**. Данный этап включает в себя следующие задачи:\n",
    "* Определение источников текста. Текст может иметь цифровую форму или быть написан на бумаге, может находится внутри или за пределами исследуемой организации.\n",
    "* Оценка доступности и применимости данных.\n",
    "* Сбор первичных данных.\n",
    "* Оценка содержательности данных (содержится ли в них необходимая для исследования информация).\n",
    "* Оценка количества и качества данных.\n",
    "\n",
    "После того, как разведывательная часть исследования успешно завершена, можно приступить к сбору данных из различных источников. Как это делать, мы уже проходили.\n",
    "\n",
    "**Этап 3. Подготовка данных**. Подготовка данных – необходимый для text mining этап, ведь специфика данного метода по сравнению с data mining заключается в более трудоёмких стадиях сбора и обработки данных.\n",
    "\n",
    "Этап подготовки данных состоит из следующих фаз:\n",
    "* Создание корпуса. В лингвистике корпус – это большой структурированный набор текстов. На данном этапе необходимо собрать все текстовые документы, относящиеся к исследуемой проблеме. Исследователю предстоит решить, какие данные и в каких объёмах необходимо собрать и проанализировать, чтобы решить поставленную задачу. Следует помнить, что все методы data mining сильно зависимы от точности полученных результатов от их количества. После того, как документы будут собраны, их необходимо трансформировать таким образом, чтобы они были представлены в единой форме (например, в базе данных или текстовом файле) для компьютерной обработки.\n",
    "* Предварительная обработка данных. Об этом ниже.\n",
    "\n",
    "**Этап 4. Разработка и калибровка модели**. На этом этапе происходит применение методов извлечения знаний.\n",
    "\n",
    "**Этап 5. Проверка результатов**. После того, как модель создана и настроена, мы должны произвести общую проверку всех действий. Например, необходимо убедиться, что выборка произведена правильно. Также случается, что в процессе построения исследования теряется основная цель, для достижения которой оно начиналось. На данном этапе следует проверить, решает ли модель сформулированную проблему и служит ли, таким образом, достижению цели. Если что-то упущено, необходимо вернуться назад к этапу, породившему рассогласованность между целью и результатом.\n",
    "\n",
    "**Этап 6. Внедрение**. В случае, если по итогам проверок было решено, что модель решает поставленную проблему, её можно применять. В самом простом случае внедрение может принимать форму написания отчёта о результатах исследования (в вашем случае — курсовой работы). В сложном – построение интеллектуальной системы на основе построенной модели с тем, чтобы она могла быть повторно использована для принятия решений.\n",
    "\n",
    "# Область применения и примеры использования методов интеллектуального анализа текста\n",
    "Интеллектуальный анализ текста находит своё применение во многих областях. В экономике с его помощью можно установить, как настроения в СМИ влияют на котировки фондового рынка [1] имеется ли связь между отзывами о продукте в Интернет-магазине и его продажами [2], как макроэкономические показатели могут быть измерены поисковыми запросами [3] и текстами из социальных медиа.\n",
    "\n",
    "В психологии этот метод позволяет узнать, как психическое состояние человека выражается в его языке [4] и правда ли, что суточные и сезонные циклы настроения носят надкультурный характер [5].\n",
    "\n",
    "Одним из самых известных и ранних примеров применения методов text mining в исторических исследованиях является установление авторства сборника статей «Федералист» [6]. Здесь text mining принял форму стилометрии.\n",
    "\n",
    "Социолингвисты использовали text mining для идентификации географически зависимых лингвистических переменных и, на основании этого, предсказания местоположения пользователя на основе написанного им текста [7].\n",
    "Text-mining также можно использовать в качестве вспомогательного метода, уточняющего результаты традиционных опросов [8].\n",
    "Рассматриваемый метод активно используется в политологических и социологических исследованиях.\n",
    "\n",
    "1. C. Tetlock Paul. Giving content to investor sentiment: The role of media in the stock mar- ket // The Journal of Finance. — 2007. — June. — Vol. 62, no. 3. — Pp. 1139–1168.\n",
    "2. ArchakNikolay,GhoseAnindya,IpeirotisPanagiotis.Derivingthepricingpowerofproductfeatures by mining consumer reviews [Online] // Management Science. — 2011. — August. — Vol. 57, no. 8. — Pp. 1485–1509. — Available: http://pages.stern.nyu.edu/~aghose/pricingpower_print.pdf.\n",
    "3. Askitas Nikolaos, Zimmermann Klaus F. Google econometrics and unemployment forecasting [Online] // Applied Economics Quarterly. — 2009. — April. — Vol. 55, no. 2. — Pp. 107–120. — Available: http://ftp.iza.org/dp4201.pdf.\n",
    "4. Tausczik Yla R., Pennebaker James W. The Psychological Meaning of Words: LIWC and Comput- erized Text Analysis Methods [Online] // Journal of Language and Social Psychology. — 2010. — Vol. 29, no. 1. — Pp. 24–54. — Available: http://homepage.psy.utexas.edu/HomePage/Faculty/Pennebaker/Reprints/Tausczik&Pennebaker2010.pdf.\n",
    "5. Golder Scott A., Macy Michael W. Diurnal and Seasonal Mood Vary with Work, Sleep, and Daylength Across Diverse Cultures [Online] // Science. — 2011. — September. — Vol. 333. — Pp. 1878–1881. — Available: http://www3.ntu.edu.sg/home/linqiu/teaching/psychoinformatics/DiurnalandSeasonalMoodVaryAcrossDiverseCultures.pdf.\n",
    "6. Mosteller F., Wallace D.L., Nerbonne J. Inference and Disputed Authorship: The Federalist. The David Hume Series. — Center for the Study of Language and Information, 2008.\n",
    "7. A Latent Variable Model for Geographic Lexical Variation [Online] / Jacob Eisenstein, Brendan O’Connor, Noah A. Smith, Eric P. Xing // Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing. — 2010. — Pp. 1277–1287. — Available: http://www.cs.cmu.edu/~nasmith/papers/eisenstein+oconnor+smith+xing.emnlp10.pdf.\n",
    "8. From Tweets to Polls: Linking Text Sentiment to Public Opinion Time Series [Online] / Bren- dan O’Connor, Ramnath Balasubramanyan, Bryan R. Routledge, Noah A Smith // Internation- al AAAI Conference on Weblogs and Social Media. — Washington: 2010. — Available: http://www.cs.cmu.edu/~nasmith/papers/oconnor+balasubramanyan+routledge+smith.icwsm10.pdf.\n",
    "\n",
    "\n",
    "# Особенности работы с текстами\n",
    "\n",
    "Автоматический анализ текстов — наверное, самая сложный раздел анализа данных и предмет отдельных дисциплин, таких как компьютерная лингвистика, обработка естественного языка и др. В работе с текстами очень важно осознавать особенности этого типа данных на каждом цикле:\n",
    "\n",
    "1. Сбор и хранение текстов, построение корпуса.\n",
    "2. Предварительная обработка текстов.\n",
    "3. Кодирование текстов (не обязательно).\n",
    "4. Применение методов анализа\n",
    "\n",
    "Особенности анализа текстов:\n",
    "0. Зависимость от языка.\n",
    "1. Сложная многоуровная структура (морфология, синтаксис, семантика), которая для компьютера по умолчанию выглядит как отсутствите структуры.\n",
    "2. При анализе текстов этап предварительной обработки имеет намного большее значение, чем при анализе других видов информации, т.к. благодаря этому текст обретает структуру.\n",
    "3. Как следствие, существуют особенные методы предварительной обработки и выявления признаков:\n",
    "    * токенизация\n",
    "    * лемматизация, стемминг\n",
    "    * удаление стоп-слов\n",
    "    * n-граммы (на уровне символов и на уровне слов)\n",
    "    * обогащение контекстом: word2vec, doc2vec, etc.\n",
    "    * сочетания методов (phrases из gensim)\n",
    "    * выявление синтаксически связанных словосочетаний (typed dependences)\n",
    "    * ...\n",
    "4. Особенности кодирования текстов: кодирование сложных концептов вызывает большие затруднения у людей, поскольку эти концепты выражают сложные и многослойные идеи ([Measuring the Reliability of Hate Speech Annotations: The Case of the European Refugee Crisis](https://arxiv.org/abs/1701.08118)).\n",
    "5. Помимо общих в анализе текста существуют и специализированные задачи (некоторые из них пересекаются с методами предварительной обработки, но могут использоваться как самостоятельные методы анализа):\n",
    "    * классификация\n",
    "    * кластеризация (тематическое моделирование)\n",
    "    * анализ тональности, blame attribution\n",
    "    * выявление коллокаций\n",
    "    * распознавание именованных сущностей (named-entity recognition)\n",
    "    * синтаксический парсинг\n",
    "    * генерация текста ([формирование аннотаций](https://machinelearningmastery.com/gentle-introduction-text-summarization/), [рефератов](https://yandex.ru/referats/?t=marketing&s=43279), [текстов песен](https://music.yandex.ru/artist/4445922), [формирование подписей к изображениям](https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/)), определение ключевых слов\n",
    "    * диалоговые системы, чат-боты\n",
    "    * машинный перевод\n",
    "    * ...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "> <font size=\"30\">Практика</font>\n",
    "\n",
    "> Чтобы получить представление о текущем состоянии дел в одной из практических областей обработки естественного язкыа — выявлении языка вражды — прочитайте статью «[A Survey on Hate Speech Detection using Natural Language Processing](http://www.aclweb.org/anthology/W17-1101)». \n",
    "1. Какие основные методы извлечения признаков из текстов выделяют авторы?\n",
    "2. Какие методы классификации чаще всего используются в этой сфере?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сбор и хранение данных\n",
    "Про сбор данных мы уже говорили, так что несколько слов про хранение.\n",
    "\n",
    "Избегайте хранить структурированные текстовые данные в текстовом формате типа CSV. В случае, если в текстах встретится символ, используеммый в этом файле качестве разделителя, вся структура сломается.\n",
    "\n",
    "Храните текстовые данные в кодировке utf8.\n",
    "\n",
    "Если данные помещаются с оперативную память, то их можно хранить в любом бинарном формате как один файл ([форматы хранения pandas dataframes](http://pandas.pydata.org/pandas-docs/stable/io.html)). Иначе используйте базы данных, предпочтительно документо-ориентированные типа MongoDB.\n",
    "\n",
    "\n",
    "# Препроцессинг\n",
    "## Выделение нужной части текста\n",
    "Для этого полезны [регулярные выражения](./regexp.ipynb).\n",
    "## Сегментация и токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "from nltk import word_tokenize\n",
    "\n",
    "with open(\"text1.txt\") as f:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Лемматизация / стемминг\n",
    "\n",
    "\n",
    "## Удаление стоп слов\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
